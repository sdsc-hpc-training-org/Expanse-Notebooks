{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Information\n",
    "---\n",
    "**Author**:\n",
    "\n",
    "**Last Updated Date**: October 01, 2024 by Gloria Seo\n",
    "\n",
    "**Resources**: https://medium.com/analytics-vidhya/sequence-model-time-series-prediction-using-tensorflow-2-0-665257beb25f\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "This Jupyter Notebook demonstrates how to build a simple time series forecasting model using TensorFlow. Specifically, we are working with historical data of the exchange rate between USD and INR (Indian Rupee), which we will download as a CSV file. The goal is to predict future values based on past trends using a sequential deep learning model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download a CSV file containing USD to INR exchange rates from the internet. This data will be stored locally and used to train the forecasting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget: /cm/shared/apps/spack/cpu/opt/spack/linux-centos8-zen/gcc-8.3.1/anaconda3-2020.11-da3i7hmt6bdqbmuzq6pyt7kbm47wyrjp/lib/libuuid.so.1: no version information available (required by wget)\n",
      "--2025-03-31 21:54:56--  https://raw.githubusercontent.com/satishnaidu/mldata/master/timeseries/USD_INR.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 130380 (127K) [text/plain]\n",
      "Saving to: ‘/tmp/USD_INR.csv’\n",
      "\n",
      "/tmp/USD_INR.csv    100%[===================>] 127.32K  --.-KB/s    in 0.005s  \n",
      "\n",
      "2025-03-31 21:54:56 (24.8 MB/s) - ‘/tmp/USD_INR.csv’ saved [130380/130380]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the CSV file using wget\n",
    "!wget --no-check-certificate https://raw.githubusercontent.com/satishnaidu/mldata/master/timeseries/USD_INR.csv -O /tmp/USD_INR.csv\n",
    "\n",
    "# Define the file path\n",
    "file_path = '/tmp/USD_INR.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Modules for the Jupyter Notebook\n",
    "Before running the notebook, make sure to load these modules.\n",
    "\n",
    "**Module: tensorflow, numpy, csv, matplotlib** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d0e44b7e237f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Data\n",
    "To better understand the dataset, we will first visualize the exchange rates over time. The CSV file is read, and the relevant columns (date and exchange rate) are extracted for plotting. A function plot_series() is used to neatly display the time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
    "    plt.plot(time[start:end], series[start:end], format)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = []\n",
    "inr_conversion = []\n",
    "with open(file_path, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        inr_conversion.append(float(row[2]))\n",
    "        time_step.append(int(row[0]))\n",
    "        \n",
    "print(inr_conversion[len(time_step)-1])\n",
    "series = np.array(inr_conversion)\n",
    "time = np.array(time_step)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_series(time, series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code visualizes the USD-INR exchange rate over time, giving a sense of how the currency value fluctuates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the data into two parts:\n",
    "\n",
    "1. Training Data: Used to train the model.\n",
    "2. Validation Data: Used to test how well the model performs on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_time = 2000\n",
    "time_train = time[:split_time]\n",
    "x_train = series[:split_time]\n",
    "time_valid = time[split_time:]\n",
    "x_valid = series[split_time:]\n",
    "window_size = 60\n",
    "batch_size = 100\n",
    "shuffle_buffer_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Windowed Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A time series prediction model learns better when we provide it with small \"windows\" of data points. The windowed_dataset() function helps create batches of sequential data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    ds = ds.shuffle(shuffle_buffer)\n",
    "    ds = ds.map(lambda w: (w[:-1], w[1:]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "The model is built using a sequential structure that includes:\n",
    "\n",
    "Convolutional Layers: Extracts patterns from the time series data.\n",
    "\n",
    "LSTM (Long Short-Term Memory) Layers: Excellent for learning from sequential data.\n",
    "\n",
    "Dense Layers: Final layers for producing the output predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forecast(model, series, window_size):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
    "    ds = ds.batch(32).prefetch(1)\n",
    "    forecast = model.predict(ds)\n",
    "    return forecasttf.random.set_seed(51)\n",
    "\n",
    "np.random.seed(51)\n",
    "train_set = windowed_dataset(x_train, window_size=120,\n",
    "                             batch_size=100,\n",
    "                             shuffle_buffer=shuffle_buffer_size)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv1D(filters=60, kernel_size=5,\n",
    "                         strides=1,padding=\"causal\",\n",
    "                         activation=\"relu\",input_shape=[None, 1]),\n",
    "  tf.keras.layers.LSTM(60, return_sequences=True),\n",
    "  tf.keras.layers.LSTM(60, return_sequences=True),\n",
    "  tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(1),\n",
    "  tf.keras.layers.Lambda(lambda x: x * 400)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=51e-7, momentum=0.9)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.Huber(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"mae\"])\n",
    "history = model.fit(train_set,epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Updated Date and Resources\n",
    "---\n",
    "**Last Updated Date**: October 01, 2024\n",
    "\n",
    "**Resources**: https://medium.com/analytics-vidhya/sequence-model-time-series-prediction-using-tensorflow-2-0-665257beb25f\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Ticket\n",
    "If you find anything that needs to be changed, edited, or if you would like to provide feedback or contribute to the notebook, please submit a ticket by contacting us at:\n",
    "\n",
    "Email: consult@sdsc.edu\n",
    "\n",
    "We appreciate your input and will review your suggestions promptly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
