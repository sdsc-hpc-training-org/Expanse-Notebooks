{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "This notebook demonstrates how to leverage the **Dask** library alongside NumPy and MKL for efficient array processing. The primary goal is to illustrate the advantages of parallel processing, particularly how Dask can handle larger-than-memory datasets by chunking the data and executing operations concurrently using multiple threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Modules for the Jupyter Notebook\n",
    "**Module: mkl,da,numpy** \n",
    "\n",
    "Ensure that the software environment is properly set up to load these modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mkl\n",
    "import numpy as np\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process an array with multiple threads\n",
    "\n",
    "Multiple threads to process simultaneously different parts of the same array. `dask` automatically provides this feature by replacing the `numpy` function with `dask` functions. The key concept is a chunk, each chunk of data is executed separately by different threads. For example for a matrix we define a 2D block size and each of those blocks can be executed independently and then the results accumulated to get to the final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Currently numpy on some platforms is already multithreaded thanks to Intel MKL,\n",
    "# for this example we disable multithreading\n",
    "#import mkl\n",
    "mkl.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the output is 1, then MKL is successfully restricted to using one thread, and your environment is correctly set up to perform single-threaded computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a 2D array with 20,000 rows and 4,000 columns using the Numpy function **numpy.random.rand()**. This function will generate random numbers between 0 and 1, uniformly distributed, to populate the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.rand(20000,4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87994796, 0.1126094 , 0.54094229, ..., 0.87440272, 0.93519058,\n",
       "        0.11257881],\n",
       "       [0.87430053, 0.85287911, 0.42298797, ..., 0.03867527, 0.27968843,\n",
       "        0.02246341],\n",
       "       [0.27810658, 0.88910386, 0.4791533 , ..., 0.98192612, 0.8885504 ,\n",
       "        0.69478787],\n",
       "       ...,\n",
       "       [0.54834815, 0.20210413, 0.01712134, ..., 0.09009374, 0.24191001,\n",
       "        0.45682417],\n",
       "       [0.66792487, 0.13783056, 0.77971882, ..., 0.60420015, 0.61608451,\n",
       "        0.71115639],\n",
       "       [0.05417205, 0.63275994, 0.2387579 , ..., 0.42738878, 0.45551214,\n",
       "        0.55014156]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`%whos` is a magic function provided by `IPython` that gives memory consumption of defined variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable   Type       Data/Info\n",
      "-------------------------------\n",
      "A          ndarray    20000x4000: 80000000 elems, type `float64`, 640000000 bytes (610.3515625 Mb)\n",
      "da         module     <module 'dask.array' from<...>/dask/array/__init__.py'>\n",
      "mkl        module     <module 'mkl' from '/cm/s<...>ackages/mkl/__init__.py'>\n",
      "np         module     <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's perform some operations on the matrix in pure `numpy`, using a single thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.14 s, sys: 158 ms, total: 3.3 s\n",
      "Wall time: 3.34 s\n"
     ]
    }
   ],
   "source": [
    "%time B = A**2 + np.sin(A) * A * np.log(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing with dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a chunked `dask` array from the `numpy` array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_dask = da.from_array(A, chunks=(2000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_dask.numblocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then replace each function with the equivalent provided by `dask`, it implements most of the `numpy` functions and operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_B = (A_dask**2 + da.sin(A_dask) * A_dask * da.log(A_dask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.48 s, sys: 151 ms, total: 3.63 s\n",
      "Wall time: 3.64 s\n"
     ]
    }
   ],
   "source": [
    "%time B_dask = compute_B.compute(num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.5 s, sys: 132 ms, total: 3.63 s\n",
      "Wall time: 1.91 s\n"
     ]
    }
   ],
   "source": [
    "%time B_dask = compute_B.compute(num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time B_dask = compute_B.compute(num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time B_dask = compute_B.compute(num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(B, B_dask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author**: Bob Sinkovits \n",
    "\n",
    "**Last Updated Date**: October 01, 2024\n",
    "\n",
    "**Resources**: https://github.com/sinkovit/PythonSeries"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
